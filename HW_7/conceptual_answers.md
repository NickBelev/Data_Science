1. Found data is that which is produced for non-data-science purposes, but that you have repurposed in your data science project.  Examples include social media content (posts, their texts, metadata like likes, comments, shares), pre-existing surveys, and public information collected by the government.  Conversely, designed data is curated and generated for the current project, using a more design-by-contract approach to determine what data is needed and how to create it from existing resources.  This usually involves the data scientist coordinating with the data collection expert (for example a biologist processing cell samples to give the necessary information for all the samples to the data scientist to annotate further and analyze).

2. Sampling is necessary when the population on which you want to conduct a data science study on is too vast and overwhelming to reasonably run computations on, and so you collect a representation of the population using sampling techniques.  Note that for random / systematic sampling of a population this assumes we at least know which parties we can survey to obtain usable data.  Moreover, to avoid re-sampling, we must have some ID system to keep track of who we've already sampled.  Sometimes finding the population to actually survey is difficult so snowball sampling is employed to recruit new individuals to survey using already-sampled individuals who reach out to their network.  This is a breadth-first exploration of the space of this population that we are studying.

3. APIs are offered by companies that wish to make their data easily accessible for analysis and metrics purposes by third parties.  If an API is not provided and the third party chooses to scrape the webpage for its contents, then this HTML scraper emulates a real visitor on the site and is unnecessary web traffic and a load on the web-hosting server.  Also if someone is scraping, chances are this is because the website owner / creator did not provide an API, which is often because the onwer does not want their intellectual property being seized without any benefit or compensation.  In short, if an API is provided, it is meant to facilitate content collection from the site; if not, the website owner does not want their content being "up for grabs" at anyone's convenience, and so scraping is arguably an unwelcomed work-around from the data collector's side.  It is further complicated that there is little legal precedence for web-scraping, and the site owners winning a lawsuit depends on the quantity scraped, loss of intellectual property, how the data was used, etc.  Thus, it makes sense that they would be unhappy about their website being scraped.